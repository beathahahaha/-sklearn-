{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1b33d81-99b4-414c-98d2-a08a1179c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    " \n",
    "train_data = pd.read_csv('dataTrain.csv')\n",
    "test_data = pd.read_csv('dataA.csv')\n",
    "data = pd.concat([train_data,test_data]).reset_index(drop=True)\n",
    "\n",
    "#查看各个特征的名称和数据类型\n",
    "display(data.info())\n",
    "\n",
    "# 判断训练集和测试集中是否有缺失值，若有，则打印比例\n",
    "def judge_missing(df):\n",
    "    if(df.columns[df.isnull().any()].tolist()==[]):\n",
    "        print(\"    there's no missings\")\n",
    "        return\n",
    "    else:\n",
    "        t = df.isnull().sum()/len(df)*100\n",
    "        t = t[t>0]\n",
    "        t = t.sort_values(ascending = False)\n",
    "        missing_df = pd.DataFrame({'Features':list(t.index),'Percentage of Missings':list(t)})\n",
    "        print(missing_df)\n",
    "        \n",
    "print(\"train:\")\n",
    "judge_missing(train_data)  \n",
    "print(\"test:\")\n",
    "judge_missing(test_data)\n",
    "\n",
    "#暴力人工特征\n",
    "train_data['f47'] = train_data['f1'] * 10 + train_data['f2']\n",
    "test_data['f47'] = test_data['f1'] * 10 + test_data['f2']\n",
    "\n",
    "\n",
    "#暴力连续值 + - * /组合\n",
    "# 暴力Feature 位置\n",
    "loc_f = ['f1', 'f2', 'f4', 'f5', 'f6']\n",
    "for df in [train_data, test_data]:\n",
    "    for i in range(len(loc_f)):\n",
    "        for j in range(i + 1, len(loc_f)):\n",
    "            df[f'{loc_f[i]}+{loc_f[j]}'] = df[loc_f[i]] + df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}-{loc_f[j]}'] = df[loc_f[i]] - df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}*{loc_f[j]}'] = df[loc_f[i]] * df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}/{loc_f[j]}'] = df[loc_f[i]] / (df[loc_f[j]]+1)\n",
    "\n",
    "# 暴力Feature 通话\n",
    "com_f = ['f43', 'f44', 'f45', 'f46']\n",
    "for df in [train_data, test_data]:\n",
    "    for i in range(len(com_f)):\n",
    "        for j in range(i + 1, len(com_f)):\n",
    "            df[f'{com_f[i]}+{com_f[j]}'] = df[com_f[i]] + df[com_f[j]]\n",
    "            df[f'{com_f[i]}-{com_f[j]}'] = df[com_f[i]] - df[com_f[j]]\n",
    "            df[f'{com_f[i]}*{com_f[j]}'] = df[com_f[i]] * df[com_f[j]]\n",
    "            df[f'{com_f[i]}/{com_f[j]}'] = df[com_f[i]] / (df[com_f[j]]+1)\n",
    "\n",
    "\n",
    "#离散值编码\n",
    "def category_encode(train, test):\n",
    "    data = pd.concat([train,test]).reset_index(drop=True)\n",
    "    for col in data.columns[data.dtypes == 'object']:\n",
    "        lb = LabelEncoder()\n",
    "        lb.fit(data[col])\n",
    "        train[col] = lb.transform(train[col])\n",
    "        test[col] = lb.transform(test[col])\n",
    "category_encode(train_data, test_data)\n",
    "\n",
    "\n",
    "#生成有用特征列（去掉id和label列），训练集，测试集，标签\n",
    "feature_columns = [i for i in train_data.columns if i not in ['id','label']]  #此处需要人工定义，若要模块化，需要规范定义输入数据格式\n",
    "target = 'label'\n",
    "\n",
    "train = train_data[feature_columns]\n",
    "label = train_data[target]\n",
    "\n",
    "test = test_data[feature_columns]\n",
    "\n",
    "\n",
    "def model_train(model, model_name, kfold=5):\n",
    "    global model_name_list, final_auc_list, cost_minutes_list\n",
    "    \n",
    "    start_t = time.time()\n",
    "    oof_preds = np.zeros((train.shape[0]))\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    skf = StratifiedKFold(n_splits=kfold)\n",
    "    print(f\"Model = {model_name}\")\n",
    "    model_name_list.append(model_name)\n",
    "    for k, (train_index, test_index) in enumerate(skf.split(train, label)):\n",
    "        x_train, x_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
    "        y_train, y_test = label.iloc[train_index], label.iloc[test_index]\n",
    "\n",
    "        model.fit(x_train,y_train)\n",
    "\n",
    "        y_pred = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "        #oof_preds[test_index] = y_pred.ravel()\n",
    "        oof_preds[test_index] = y_pred\n",
    "\n",
    "        auc = roc_auc_score(y_test,y_pred)\n",
    "        print(\"- KFold = %d, val_auc = %.4f\" % (k, auc))\n",
    "        test_fold_preds = model.predict_proba(test)[:, 1]\n",
    "        #test_preds += test_fold_preds.ravel()\n",
    "        test_preds += test_fold_preds\n",
    "    \n",
    "    overall_auc = roc_auc_score(label, oof_preds)\n",
    "    print(\"Overall Model = %s, AUC = %.4f\" % (model_name, overall_auc))\n",
    "    final_auc_list.append(overall_auc)\n",
    "    end_t = time.time()\n",
    "    cost_minutes = (end_t - start_t)/60\n",
    "    print(f\"cost {cost_minutes} minutes\")\n",
    "    cost_minutes_list.append(cost_minutes)\n",
    "    return test_preds / kfold\n",
    "\n",
    "\n",
    "# gbc = GradientBoostingClassifier()\n",
    "# gbc_test_preds = model_train(gbc, \"GradientBoostingClassifier\", 5)\n",
    "\n",
    "\n",
    "train = train[:50000]  #这一步需要再智能化\n",
    "label = label[:50000]\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=50, \n",
    "    learning_rate=0.1,\n",
    "    max_depth=5\n",
    ")\n",
    "hgbc = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    max_depth=5\n",
    ")\n",
    "xgbc = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1\n",
    ")\n",
    "gbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=2 ** 6, \n",
    "    max_depth=8,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample_freq=1,\n",
    "    max_bin=255,\n",
    "    learning_rate=0.05, \n",
    "    n_estimators=100, \n",
    "    metrics='auc'\n",
    ")\n",
    "cbc = CatBoostClassifier(\n",
    "    iterations=210, \n",
    "    depth=6, \n",
    "    learning_rate=0.03, \n",
    "    l2_leaf_reg=1, \n",
    "    loss_function='Logloss', \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "# model_train(clf,\"stacking\")\n",
    "# print(\"over 2!\")\n",
    "\n",
    "all_model_name = [\n",
    "    ('gbc', gbc),\n",
    "    ('hgbc', hgbc),\n",
    "    ('xgbc', xgbc),\n",
    "    ('lgbm', gbm),\n",
    "    ('cbc', cbc),\n",
    "    (\"stacking\",clf)\n",
    "]\n",
    "model_name_list = []\n",
    "final_auc_list = []\n",
    "cost_minutes_list = []\n",
    "for i in tqdm(range(len(all_model_name))):\n",
    "    model_train(all_model_name[i][1], all_model_name[i][0])\n",
    "    \n",
    "model_df = pd.DataFrame({\"model_name\":model_name_list, \"final_auc\":final_auc_list, \"cost_minutes\":cost_minutes_list})\n",
    "print(model_df)\n",
    "print(\"over\")\n",
    "\n",
    "model_df = pd.DataFrame({\"model_name\":model_name_list, \"final_auc\":final_auc_list, \"cost_minutes\":cost_minutes_list})\n",
    "model_df.sort_values(columns=\"final_auc\",replace=True)\n",
    "print(model_df)\n",
    "print(\"over\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, stratify=label, random_state=2022)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('auc = %.8f' % auc)\n",
    "\n",
    "\n",
    "ff = []\n",
    "for col in feature_columns:\n",
    "    x_test = X_test.copy() #这里容易出错，建议写成copy.deepcopy(X_test)\n",
    "    x_test[col] = 0\n",
    "    auc1 = roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1])\n",
    "    if auc1 < auc:\n",
    "        ff.append(col)  #选取有用的特征加入到ff\n",
    "    print('%5s | %.8f | %.8f' % (col, auc1, auc1 - auc))\n",
    "\n",
    "\n",
    "clf.fit(X_train[ff], y_train)\n",
    "y_pred = clf.predict_proba(X_test[ff])[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('auc = %.8f' % auc)\n",
    "\n",
    "\n",
    "train = train[ff]\n",
    "test = test[ff]\n",
    "\n",
    "clf_test_preds = model_train(clf, \"StackingClassifier\", 10)\n",
    "\n",
    "submission['label'] = clf_test_preds\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "submission = test_data\n",
    "submission['label'] = clf_test_preds\n",
    "submission[['id','label']].to_csv('submission_0911628.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
